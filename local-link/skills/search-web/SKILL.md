---
name: search-web
description: 使用 Evaluator-optimizer 模式进行系统性多轮网络搜索，确保研究质量。当用户需要深入调查复杂主题、验证假设或全面收集信息时使用。该技能采用评估器-优化器循环，其中一个子代理生成搜索结果，另一个根据定义的标准评估质量，并通过反馈驱动查询优化。触发词包括"搜索..."、"研究..."、"查找关于...的信息"、"探索..."，或当用户需要经过验证的、有质量保证的深入研究时。
---

# 网络搜索

## 概述

本技能使用 **Evaluator-optimizer 模式** 进行系统性多轮网络研究，确保结果质量。它构建搜索查询、分发并行搜索、根据质量标准评估结果，并基于结构化反馈进行迭代，直到达成研究目标。

## 工作流程

```
1. 理解研究目标
2. 构建初始搜索查询集群
3. 分发子代理搜索（并行）
4. 将结果聚合到结构化日志
5. 评估器-优化器循环：
   ├─ 评估器根据质量标准评估结果
   ├─ 生成结构化反馈
   └─ 优化器优化查询或决定完成
6. 返回经过验证的发现
```

## 步骤 1：理解研究目标

与用户澄清：
- **核心假设/问题**：我们试图验证或发现什么？
- **范围**：需要关注的具体方面（例如，基准数据、用户投诉、学术论文）
- **质量阈值**：需要多高的置信度？（高/中/低）
- **输出格式**：摘要、详细报告还是原始发现？

## 步骤 2：构建初始查询集群

创建 3-5 个相关搜索词集群，涵盖不同角度：

**集群类型：**
- **直接对比**：并排比较
- **特定基准**：具名评估数据集/框架
- **技术讨论**：GitHub issues、HN、StackOverflow
- **学术来源**：论文、arXiv、研究博客
- **负面信号**：Bug、限制、投诉

为每个集群准备：
- 主要英文查询
- 替代表述（2-3 种变体）
- 中文查询（如相关）
- 目标站点（例如 `site:github.com`、`site:arxiv.org`）

有关高级查询构建技巧，请参阅 [references/search-strategies.md](references/search-strategies.md)。

## 步骤 3：分发子代理搜索

使用 Task 工具配合 `subagent_type: general-purpose` 启动并行搜索。

**搜索代理配置：**
```yaml
name: search-agent-{n}
prompt: |
  搜索："{query}"

  目标：{research_goal}

  使用 WebSearch 工具执行网络搜索。
  对于每个相关结果：
  1. 使用 WebFetch 或浏览器工具获取页面内容
  2. 提取与研究目标相关的关键发现
  3. 记录：URL、标题、要点、相关度评分（1-5）

  以以下格式返回结构化结果：
  ```
  ## {query}

  ### 结果 1：{title}
  - URL: {url}
  - 相关度：{1-5}/5
  - 关键发现：
    - {要点}
  - 引用：
    - "{相关摘录}"
  ```

  如果结果不足，尝试变体查询。
  关注事实信息和有数据支持的论断。
```

**并行启动 3-5 个代理**，每个代理使用不同的查询集群。

## 步骤 4：聚合结果

### 4.1 初始化会话目录

```bash
mkdir -p /tmp/search-web/{YYYY-MM-DD}/{task-name}
```

### 4.2 创建主日志文件

将聚合结果写入 `/tmp/search-web/{YYYY-MM-DD}/{task-name}/master-log.md`：

```markdown
# 搜索会话：{task-name}
日期：{YYYY-MM-DD}
目标：{research_goal}

## 执行的查询集群
1. {集群 1 描述}
2. {集群 2 描述}
...

## 按集群分类的搜索结果

### 集群 1：{name}
{子代理结果}

### 集群 2：{name}
{子代理结果}
```

## 步骤 5：评估器-优化器循环

这是核心创新。不使用简单的完成检查，而是使用两个子代理形成反馈循环：

### 5.1 评估器代理

分发评估器来评估搜索质量：

```yaml
name: search-evaluator
prompt: |
  你是研究质量评估器。根据我们的研究目标和质量标准评估以下搜索结果。

  研究目标：{goal}

  搜索结果：
  {aggregated_results}

  从以下维度评估（每项 1-5 分）：

  1. **覆盖度** - 结果是否从多个角度回答了核心问题？
     - 5：所有关键角度都有深度覆盖
     - 3：大部分角度已覆盖，但仍有缺口
     - 1：重大缺口，缺少关键视角

  2. **来源质量** - 来源是否权威可信？
     - 5：多个权威来源（官方文档、论文、GitHub 官方）
     - 3：好坏来源混合
     - 1：主要是低质量或未经核实的来源

  3. **一致性** - 来源在关键事实上是否一致？
     - 5：强烈共识，仅有微小差异
     - 3：注意到一些矛盾但未解决
     - 1：重大矛盾未解决

  4. **具体性** - 论断是否有数据/案例支持？
     - 5：贯穿始终的具体数字、基准、示例
     - 3：有一些具体信息，也有一些概括
     - 1：主要是没有证据的模糊论断

  5. **时效性** - 信息是否最新且相关？
     - 5：包含最新进展，注明日期
     - 3：大部分最新，一些较旧但仍相关
     - 1：明显过时的信息

  以以下格式返回你的评估：

  ```
  ## 质量评估

  | 维度 | 评分 | 依据 |
  |------|------|------|
  | 覆盖度 | {1-5} | {简要说明} |
  | 来源质量 | {1-5} | {简要说明} |
  | 一致性 | {1-5} | {简要说明} |
  | 具体性 | {1-5} | {简要说明} |
  | 时效性 | {1-5} | {简要说明} |

  **总分**：{average}/5

  ## 缺口分析

  缺失或需要改进的内容：
  1. {具体缺口 1}
  2. {具体缺口 2}
  ...

  ## 改进建议

  为解决缺口，搜索：
  1. {具体后续查询 1}
  2. {具体后续查询 2}
  ...

  ## 完成评估

  - [ ] 足以回答核心问题：{是/否}
  - [ ] 多个来源证实关键论断：{是/否}
  - [ ] 矛盾已记录并解决：{是/否}
  - [ ] 可以分配置信度：{是/否}

  **建议**：{CONTINUE_SEARCH / COMPLETE}
  ```
```

### 5.2 决策点

基于评估器输出：

**如果 COMPLETE：**
- 进入步骤 6
- 在主日志中记录最终评估

**如果 CONTINUE_SEARCH：**
- 提取改进建议
- 基于缺口构建新的查询集群
- 返回步骤 3（最多 4 轮）

### 5.3 优化器代理（复杂情况可选）

对于复杂研究，使用优化器来优化查询：

```yaml
name: query-optimizer
prompt: |
  你是搜索查询优化器。基于评估器反馈，优化我们的搜索策略。

  原始目标：{goal}
  评估器反馈：{evaluator_feedback}
  先前查询：{previous_queries}

  生成 2-3 个新的查询集群，专门解决已识别的缺口。
  避免重复先前的查询。

  返回：
  ```
  ## 优化的查询集群

  ### 集群：{具体缺口名称}
  - 主要："{优化后的查询}"
  - 变体：
    - "{变体 1}"
    - "{变体 2}"
  - 目标站点：{特定站点（如适用）}
  - 理由：{为什么这能解决缺口}
  ```
```

## 步骤 6：交付经过验证的结果

### 6.1 最终摘要

向用户提供：

```markdown
## 研究摘要

### 执行摘要
{回答核心问题的 2-3 段文字}

### 关键发现（含置信度）
| 发现 | 证据 | 置信度 |
|------|------|--------|
| {要点 1} | {来源} | 高/中/低 |
| {要点 2} | {来源} | 高/中/低 |

### 质量评估
- 覆盖度：{score}/5 - {简要说明}
- 来源质量：{score}/5 - {简要说明}
- 一致性：{score}/5 - {简要说明}

### 局限性
{仍不确定或需要进一步调查的内容}

### 来源
{带 URL 的关键引用}
```

### 6.2 主日志位置

向用户指出详细日志：
> 完整搜索会话日志：`/tmp/search-web/{YYYY-MM-DD}/{task-name}/master-log.md`

### 6.3 可选的用户审核

询问：
- "研究完成，质量评分 {X}/5。是否足够？"
- "你是否希望我深入调查任何特定发现？"

## 带评估器反馈的多轮协议

**第 1 轮：广泛探索**
- 用通用查询撒大网
- 评估器识别关键缺口

**第 2 轮：针对性调查**
- 解决第 1 轮评估中的具体缺口
- 搜索矛盾证据

**第 3 轮+：深入挖掘**
- 关注评估器中未解决的问题
- 搜索主要来源以填补缺口

**停止条件：**
- 评估器建议 COMPLETE
- 收益递减（评估器指出无显著改进）
- 达到轮次限制（默认：4）
- 用户满意

## 质量标准参考

有关详细评分标准和示例，请参阅 [references/quality-criteria.md](references/quality-criteria.md)。

## 子代理脚本

对于复杂搜索，使用 [scripts/search_agent.py](scripts/search_agent.py)：

```bash
python3 scripts/search_agent.py "{query}" --output /tmp/search-web/{date}/{task}/
```

对于评估，使用 [scripts/evaluator.py](scripts/evaluator.py)：

```bash
python3 scripts/evaluator.py --log /tmp/search-web/{date}/{task}/master-log.md
```

## 最佳实践

1. **评估器是必需的**：永远不要跳过质量评估
2. **反馈要具体**：模糊的"再搜索一下"没有帮助
3. **跟踪质量趋势**：如果分数没有提高，重新考虑方法
4. **记录评估器输出**：每次评估对透明度都很有价值
5. **知道何时停止**：完美的研究是不可能的；足够好通常就足够了

## 示例会话

**用户请求**："搜索 LLM 代理在 PowerShell 上表现比 Bash 差的证据"

**第 1 轮：**
- 查询：通用比较、基准搜索
- 评估器："覆盖度 3/5 - 需要更具体的基准；来源质量 4/5；具体性 2/5 - 需要实际数字"
- 建议：CONTINUE

**第 2 轮：**
- 查询：SWE-bench 结果、pass@k 指标、GitHub issue 分析
- 评估器："覆盖度 4/5；具体性 4/5 - 找到好数据；一致性 3/5 - 一些矛盾论断需要解决"
- 建议：CONTINUE

**第 3 轮：**
- 查询：关注矛盾论断、主要来源
- 评估器："所有维度 4+/5。足以回答核心问题。"
- 建议：COMPLETE

**交付物**：带置信度评分和质量评估的验证摘要

---

## 时效性搜索指南

**当前日期：2026-02-27**

进行搜索时，请注意信息的时效性：

### 时效性敏感主题

为以下内容添加时效性过滤器或时间限定查询：
- **技术版本**（软件发布、框架更新）
- **市场数据**（价格、趋势、统计）
- **时事**（新闻、法规、政策）
- **研究论文**（最新发表、SOTA 结果）

### 时效性查询模式

```
# 最新版本
"{topic} latest version 2025 2026"
"{topic} release notes 2026"

# 当前最佳实践
"{topic} best practices 2025"
"{topic} guide 2026"

# 破坏性变更
"{topic} breaking changes 2025 2026"
"{topic} migration guide"

# 研究
"{topic} paper 2025 2026"
"{topic} benchmark 2025"
```

### 评估器的时效性调整

评估结果时，请考虑搜索日期：
- 2024-2026 年的信息：当前（正常权重）
- 2023 年的信息：对于快速发展的领域可能已过时
- 2022 年或更早的信息：对于技术主题可能已过时

相应调整**时效性**评分，并标记可能过时的关键信息。
